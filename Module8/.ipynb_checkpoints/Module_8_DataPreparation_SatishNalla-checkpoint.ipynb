{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e0c566e-8312-4e6d-9696-9bf40a7ceb2e",
   "metadata": {},
   "source": [
    "# Data Preperation for the Project - Historical MRTS Sales Analysis\n",
    "\n",
    "**Satish Nalla**\n",
    "\n",
    "with the various Years of data for each Kind of business with multiple Adjustment Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2e905-215e-4761-b11e-5b645350457d",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "- [Abstract](#Abstract)\n",
    "- [1. Initialization](#1.-Initialization)\n",
    "- [2. Importing the Data](#2.-Importing-the-Data)\n",
    "- [3. Exploring the Data](#3.-Exploring-the-Data)\n",
    "- [4. Finalizing the Data](#4.-Finalizing-the-data-and-preparing-the-Installation-Scripts)\n",
    "- [5. Conclusion](#5.-Conclusion)\n",
    "- [6. References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f1fad-9a0b-4f0a-8b03-0ec08ea9e707",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7818be-291f-4227-b172-6454df217158",
   "metadata": {},
   "source": [
    "In order to import the MRTS Sales data which has one worksheet per year and the data is more in reporting format with various columns and sections, the Goal is to cleanse the data and get into uniform format and preparing the Installation Scripts to load it into database for further Analysis and the Project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2020e1-c54f-49b3-8a6a-287039d611fb",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "## 1. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c704c-e5cc-410f-980c-e401b3df5176",
   "metadata": {},
   "source": [
    "Importing the Python Libraries Needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce9be545-898d-468c-bd24-0eb10bcf2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5a2a6-353c-4f00-bd07-aa2c460c783e",
   "metadata": {},
   "source": [
    "Data File Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12e298a6-c9eb-4380-b566-2334dd3c570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input excel file name\n",
    "excelfile = 'mrtssales92-present.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929d0da-dd2e-4109-a489-73e0004f41df",
   "metadata": {},
   "source": [
    "Creation of f_isDate function to check if its a date value, this will be used in the code further to check the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f59a561b-09d8-40ba-84b0-0a04d2b803ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the input string is a valid date or not and returns True if input is date else false.\n",
    "def f_isDate(iStr):\n",
    "    try: \n",
    "        parse(iStr, fuzzy=False)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a877b6-cab5-428d-8c58-91b871b9135e",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "## 2. Importing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e880da4-4f29-49be-ab99-2caaa786ac50",
   "metadata": {},
   "source": [
    "using pandas getting the list of worksheets in the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a10b2d0c-232d-433e-a56e-c17a96abf7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021', '2020', '2019', '2018', '2017', '2016', '2015', '2014', '2013', '2012', '2011', '2010', '2009', '2008', '2007', '2006', '2005', '2004', '2003', '2002', '2001', '2000', '1999', '1998', '1997', '1996', '1995', '1994', '1993', '1992']\n"
     ]
    }
   ],
   "source": [
    "#Pandas has functionality for getting the list of sheets in an excel file so that will be helpful to loop through to import data\n",
    "dataFile = pd.ExcelFile(excelfile)\n",
    "sheets = dataFile.sheet_names\n",
    "\n",
    "print(sheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81084cc8-15a0-414c-b765-aaac573e242c",
   "metadata": {},
   "source": [
    "looping through each sheet and importing data and merging to the one master raw data variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d7b0bf-a247-44c5-946c-d0aba41a82a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#master_raw_data going to be the final data frame of all the data\n",
    "master_raw_data = pd.DataFrame()\n",
    "\n",
    "#looping through the all sheets and importing the data for each sheet\n",
    "for sheet in sheets:\n",
    "    raw_data_NA = ''\n",
    "    raw_data_A = ''\n",
    "    #as we have 2 sections of data Not Adjustment and Adjustment Types, loading the excel file seperately for each set of rows\n",
    "    raw_data_NA = pd.read_excel(excelfile, sheet_name = sheet, skiprows = 4, nrows = 66)\n",
    "    raw_data_A = pd.read_excel(excelfile, sheet_name = sheet, skiprows = 71, nrows = 38)\n",
    "    \n",
    "    raw_data_A.columns = raw_data_NA.columns\n",
    "\n",
    "    #Replacing the text columns to proper Date format labels.\n",
    "    newCols = {}\n",
    "    for col in raw_data_NA.columns:\n",
    "        tempCol = col\n",
    "        tempCol = tempCol.strip()\n",
    "        tempCol = tempCol.replace(\"Unnamed: 0\",\"NAICS_Code\")\n",
    "        tempCol = tempCol.replace('Unnamed: 1','Kind_of_Business')\n",
    "        tempCol = tempCol.replace('.','')\n",
    "        tempCol = tempCol.replace('Jan','01/01/')\n",
    "        tempCol = tempCol.replace('Feb','02/01/')\n",
    "        tempCol = tempCol.replace('Mar','03/01/')\n",
    "        tempCol = tempCol.replace('Apr','04/01/')\n",
    "        tempCol = tempCol.replace('May','05/01/')\n",
    "        tempCol = tempCol.replace('Jun','06/01/')\n",
    "        tempCol = tempCol.replace('Jul','07/01/')\n",
    "        tempCol = tempCol.replace('Aug','08/01/')\n",
    "        tempCol = tempCol.replace('Sep','09/01/')\n",
    "        tempCol = tempCol.replace('Oct','10/01/')\n",
    "        tempCol = tempCol.replace('Nov','11/01/')\n",
    "        tempCol = tempCol.replace('Dec','12/01/')\n",
    "        tempCol = tempCol.replace(' ','')\n",
    "        tempCol = tempCol.replace('(p)','')\n",
    "        newCols[col]= tempCol\n",
    "        #print(tempCol)\n",
    "        \n",
    "    #print(newCols)\n",
    "    \n",
    "    #Assigning the new columns names to both the Dataimport pandas dataframe variables and adding an additional column Adjustment to seperateout the data when we merge both the dataframes\n",
    "    raw_data_NA.rename(columns=newCols,inplace = True)\n",
    "    raw_data_NA = raw_data_NA.drop(raw_data_NA[(raw_data_NA.Kind_of_Business  == 'NOT ADJUSTED')].index)\n",
    "    raw_data_NA['Adjustment_Type']='NOT ADJUSTED'\n",
    "    \n",
    "    raw_data_A.rename(columns=newCols, inplace = True)\n",
    "    raw_data_A['Adjustment_Type']='ADJUSTED'\n",
    "\n",
    "    #Concatenating the Not Adjustment and Adjustment Dataframes\n",
    "    raw_data = pd.concat([raw_data_NA,raw_data_A])\n",
    "    \n",
    "    #Cleansing the data by updating the date datatypes, replacing NA with NANs and other string variables in numbers and dates to NANs for better usage further.\n",
    "    for cols in raw_data.columns:\n",
    "        if f_isDate(cols):\n",
    "            tempDataFrame = pd.DataFrame()\n",
    "            tempDataFrame = raw_data.loc[:, ['NAICS_Code', 'Kind_of_Business','Adjustment_Type',cols]]\n",
    "            tempDataFrame = tempDataFrame.astype({'NAICS_Code':'string'})\n",
    "            tempDataFrame['Date'] = pd.to_datetime(cols)\n",
    "            tempDataFrame.rename(columns = {cols : 'Value'}, inplace = True)\n",
    "            tempDataFrame.replace('(NA)', np.nan, inplace = True)\n",
    "            tempDataFrame.replace('(S)', np.nan, inplace = True)\n",
    "            #Concatenating the prepared data for each sheet to master raw data Dataframe\n",
    "            master_raw_data = pd.concat([master_raw_data,tempDataFrame])\n",
    "            \n",
    "\n",
    "#Creating Additional Columns like Year & Month for better usage\n",
    "master_raw_data['Year'] =  pd.DatetimeIndex(master_raw_data['Date']).year\n",
    "master_raw_data['Month'] =  pd.DatetimeIndex(master_raw_data['Date']).month\n",
    "\n",
    "#Resetting the Index as the master_raw_data is ready\n",
    "master_raw_data = master_raw_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da1ee4-e383-42da-87c5-1da621708d66",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "## 3. Exploring the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14204572-3d4b-49ad-8f7d-1d8cca98159a",
   "metadata": {},
   "source": [
    "Checking the master data columns and details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bf732-b2dc-4db9-96fc-58be3e7cf267",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d1aaf-1f41-4a2a-8dcf-e722c0feac01",
   "metadata": {},
   "source": [
    "Checking the top rows from master raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fda19a5-3c28-43a7-8f2d-57aa39d82104",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1f18b-cf3b-410d-a5bf-36c91ece5ec1",
   "metadata": {},
   "source": [
    "Checking the bottom rows from master raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c1246-2dbf-420a-9fdf-97fccedcfda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_raw_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de9ab8-766f-4e42-8b91-6294b6b4f012",
   "metadata": {},
   "source": [
    "Describint the master raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187e525-a0ab-40c3-b265-7e12fbd8cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26cb8f-6c21-44c4-bb7c-9377d3146592",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "## 4. Finalizing the data and preparing the Installation Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db106376-5631-447c-b904-5542003b9313",
   "metadata": {},
   "source": [
    "Creating the Insert scripts from the data frame and writing to the MRTS_SALES_DATA.SQL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59bc6a-ba61-491a-89c0-255a49a9835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "insertScriptLines = []\n",
    "#first line to be inserted in the output file to connect to the database which is used in the Schema file\n",
    "dbConnectInit = 'USE MRTSSALES;'\n",
    "insertScriptLines.append(dbConnectInit + '\\n')\n",
    "\n",
    "#Defaulting the NAICS Code to Total for the Total rows\n",
    "master_raw_data.NAICS_Code.fillna('Total',inplace = True)\n",
    "master_raw_data.Value.fillna(0,inplace = True)\n",
    "\n",
    "#Looping through the master_raw_data to create the Insert script for each row\n",
    "for index,row in master_raw_data.iterrows():\n",
    "    temp = \"\"\n",
    "    temp = \"INSERT INTO MRTSSALES_DATA (NAICS_CODE, KIND_OF_BUSINESS, ADJUSTMENT_TYPE, VALUE, DATE) VALUES('\" + row['NAICS_Code'] + \"','\" + row['Kind_of_Business'].replace(\"'\",\"''\") + \"','\" + row['Adjustment_Type'] + \"',\" + str(row['Value']) + \",'\" + row['Date'].strftime(\"%Y-%m-%d\") + \"');\"\n",
    "    insertScriptLines.append(temp + '\\n')\n",
    "\n",
    "#Opening the output file to write\n",
    "file = open('MRTS_SALES_DATA.SQL', 'r+')\n",
    "\n",
    "#delete the existing content in the file\n",
    "file.truncate(0)\n",
    "\n",
    "# Writing multiple Lines at a time\n",
    "file.writelines(insertScriptLines)\n",
    "\n",
    "# Closing file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b9658-2ae8-42c8-a65b-67236dfe2807",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a4624-de26-4233-8557-a59a16e782a9",
   "metadata": {},
   "source": [
    "the Installation file for loadin the data is ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50356fe-0915-44c3-8fc6-8052defb43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SQL File Written Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d3e55-2351-43cf-8e9d-c5fab779053d",
   "metadata": {},
   "source": [
    "[Back to top](#Index)\n",
    "\n",
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c2e5c-0341-4ce1-8e8d-4b0ccc269c34",
   "metadata": {},
   "source": [
    "Adding the References which have been used in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62441bbd-8a46-484a-8bdc-c3e75f2fe411",
   "metadata": {},
   "source": [
    "- Sayon, Shubham “File Writing Methods' https://blog.finxter.com/correct-way-to-write-line-to-file-in-python/\n",
    "\n",
    "- “Reading the Excel using Pandas” https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
